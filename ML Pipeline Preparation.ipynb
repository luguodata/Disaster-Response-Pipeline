{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import pickle\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(database_filepath):\n",
    "    \"\"\" Load dataset from the ETL processed databaseself.Separate for predictors\n",
    "        variables (X) and target variables (Y). Also, get targets' names list.\n",
    "\n",
    "    Args:\n",
    "        database_filepath (str): the saved database's path from ETL processself.\n",
    "\n",
    "    Return:\n",
    "        X: predictors subset of ETL processed dataset\n",
    "        Y: targets subset of ETL processed dataset\n",
    "        category_names: the list of target variable names.\n",
    "    \"\"\"\n",
    "    # load data from database\n",
    "    engine = create_engine('sqlite:///{}'.format(database_filepath))\n",
    "    df = pd.read_sql_table('etl_processed_data', engine)\n",
    "\n",
    "    # split training and testing dataset\n",
    "    X = df.ix[:,1:2].values[:,0]\n",
    "    Y = df.ix[:,4:].values\n",
    "\n",
    "    # get target variable names\n",
    "    category_names = df.ix[:,4:].columns.tolist()\n",
    "\n",
    "    return X, Y, category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, category_names = load_data('data/DisasterResponse.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Weather update - a cold front from Cuba that could pass over Haiti',\n",
       "       'Is the Hurricane over or is it not over',\n",
       "       'Looking for someone but no name', ...,\n",
       "       \"Proshika, operating in Cox's Bazar municipality and 5 other unions, Ramu and Chokoria, assessment, 5 kg rice, 1,5 kg lentils to 700 families.\",\n",
       "       'Some 2,000 women protesting against the conduct of the elections were teargassed as they tried to converge on the local electoral commission offices in the southern oil city of Port Harcourt.',\n",
       "       'A radical shift in thinking came about as a result of this meeting, recognizing that HIV/AIDS is at the core of the humanitarian crisis and identifying the crisis itself as a function of the HIV/AIDS pandemic.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['related',\n",
       " 'request',\n",
       " 'offer',\n",
       " 'aid_related',\n",
       " 'medical_help',\n",
       " 'medical_products',\n",
       " 'search_and_rescue',\n",
       " 'security',\n",
       " 'military',\n",
       " 'child_alone',\n",
       " 'water',\n",
       " 'food',\n",
       " 'shelter',\n",
       " 'clothing',\n",
       " 'money',\n",
       " 'missing_people',\n",
       " 'refugees',\n",
       " 'death',\n",
       " 'other_aid',\n",
       " 'infrastructure_related',\n",
       " 'transport',\n",
       " 'buildings',\n",
       " 'electricity',\n",
       " 'tools',\n",
       " 'hospitals',\n",
       " 'shops',\n",
       " 'aid_centers',\n",
       " 'other_infrastructure',\n",
       " 'weather_related',\n",
       " 'floods',\n",
       " 'storm',\n",
       " 'fire',\n",
       " 'earthquake',\n",
       " 'cold',\n",
       " 'other_weather',\n",
       " 'direct_report']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Nomalize, tokenize and lemmatize process for text\n",
    "\n",
    "    Args:\n",
    "        text (str)\n",
    "\n",
    "    Return:\n",
    "        text_lems: list of element of the text after normalization, tokenization\n",
    "        stopwords removal and lemmetization\n",
    "    \"\"\"\n",
    "    # Normailization -- lower case + remove puntuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\",\" \",text.lower())\n",
    "\n",
    "    # tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stop words\n",
    "    words = [word for word in tokens if word not in stopwords.words(\"english\")]\n",
    "\n",
    "    # stemmization\n",
    "    text_lems = [WordNetLemmatizer().lemmatize(lem).strip() for lem in words]\n",
    "\n",
    "    return text_lems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \"\"\" The model builing process to integrate all the necessary steps of model\n",
    "        training, which include data loading, transformation, model training,\n",
    "        parameter grid search, model evaluation and save the trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    # feature preprocessing pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "    ])\n",
    "\n",
    "    # grid search\n",
    "    parameters = {\n",
    "        #'clf__estimator__n_estimators': [20, 50],\n",
    "        #'clf__estimator__max_depth': [3, 6]\n",
    "        'clf__estimator__min_samples_split': [3]\n",
    "        #'clf__estimator__loss': ['log', 'hinge']\n",
    "        #'clf__estimator__penalty': ['l2']\n",
    "        #'clf__estimator__alpha': [0.001, 0.0001]\n",
    "    }\n",
    "\n",
    "    cv = GridSearchCV(pipeline, param_grid= parameters)\n",
    "\n",
    "    return cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip..._score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=None))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'clf__estimator__min_samples_split': [3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model, X_test, Y_test, category_names):\n",
    "    \"\"\" Evaluation trained model via comparing true Y_test values and predicted\n",
    "        test values\n",
    "\n",
    "    Args:\n",
    "        model: the trained model\n",
    "        X_test: subset dataframe of selected test predictors\n",
    "        Y_test: subset dataframe of selected test tragets\n",
    "        category_names: the list of traget variables name list\n",
    "\n",
    "    Return:\n",
    "        None. Classification report which includes precison, recall, f1\n",
    "        score for each target variable, and averaged f1 score of all target\n",
    "        variables  will be printed out while calling the function.\n",
    "    \"\"\"\n",
    "    # prediction on test dataset\n",
    "    Y_pred = model.predict(X_test)\n",
    "\n",
    "    # initialize aggregated avg score\n",
    "    weighted_fscore = 0\n",
    "\n",
    "    for i in np.arange(0,36,1):\n",
    "        print(\"Target:{}\".format(category_names[i]))\n",
    "        print(\"\\n\")\n",
    "        print(classification_report(Y_test[i],Y_pred[i]))\n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "        weighted_fscore += f1_score(Y_test[i],Y_pred[i], \\\n",
    "        average='weighted')\n",
    "\n",
    "    print(\"Overall average f1 score of all categories are: {}\".\\\n",
    "    format(weighted_fscore/(i+1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:related\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        36\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:request\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        28\n",
      "           1       1.00      0.62      0.77         8\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        36\n",
      "   macro avg       0.95      0.81      0.86        36\n",
      "weighted avg       0.92      0.92      0.91        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:offer\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        33\n",
      "           1       1.00      0.67      0.80         3\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        36\n",
      "   macro avg       0.99      0.83      0.89        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:aid_related\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        35\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        36\n",
      "   macro avg       0.49      0.50      0.49        36\n",
      "weighted avg       0.95      0.97      0.96        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:medical_help\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84        25\n",
      "           1       0.67      0.36      0.47        11\n",
      "\n",
      "   micro avg       0.75      0.75      0.75        36\n",
      "   macro avg       0.72      0.64      0.65        36\n",
      "weighted avg       0.74      0.75      0.72        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:medical_products\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        36\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:search_and_rescue\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        36\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:security\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        27\n",
      "           1       1.00      0.67      0.80         9\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        36\n",
      "   macro avg       0.95      0.83      0.87        36\n",
      "weighted avg       0.92      0.92      0.91        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:military\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        36\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:child_alone\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:water\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        24\n",
      "           1       1.00      0.17      0.29        12\n",
      "\n",
      "   micro avg       0.72      0.72      0.72        36\n",
      "   macro avg       0.85      0.58      0.56        36\n",
      "weighted avg       0.80      0.72      0.65        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:food\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        33\n",
      "           1       1.00      0.67      0.80         3\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        36\n",
      "   macro avg       0.99      0.83      0.89        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:shelter\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        30\n",
      "           1       1.00      0.50      0.67         6\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        36\n",
      "   macro avg       0.95      0.75      0.81        36\n",
      "weighted avg       0.92      0.92      0.90        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:clothing\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        33\n",
      "           1       0.60      1.00      0.75         3\n",
      "\n",
      "   micro avg       0.94      0.94      0.94        36\n",
      "   macro avg       0.80      0.97      0.86        36\n",
      "weighted avg       0.97      0.94      0.95        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:money\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.96        32\n",
      "           1       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        36\n",
      "   macro avg       0.96      0.62      0.68        36\n",
      "weighted avg       0.92      0.92      0.89        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:missing_people\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        30\n",
      "           1       1.00      0.67      0.80         6\n",
      "\n",
      "   micro avg       0.94      0.94      0.94        36\n",
      "   macro avg       0.97      0.83      0.88        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:refugees\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        36\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        36\n",
      "   macro avg       0.50      0.49      0.49        36\n",
      "weighted avg       1.00      0.97      0.99        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:death\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:other_aid\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        29\n",
      "           1       1.00      0.29      0.44         7\n",
      "\n",
      "   micro avg       0.86      0.86      0.86        36\n",
      "   macro avg       0.93      0.64      0.68        36\n",
      "weighted avg       0.88      0.86      0.83        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:infrastructure_related\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91        26\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "   micro avg       0.86      0.86      0.86        36\n",
      "   macro avg       0.92      0.75      0.79        36\n",
      "weighted avg       0.88      0.86      0.84        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:transport\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        36\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        36\n",
      "   macro avg       0.50      0.49      0.49        36\n",
      "weighted avg       1.00      0.97      0.99        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:buildings\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        35\n",
      "           1       0.33      1.00      0.50         1\n",
      "\n",
      "   micro avg       0.94      0.94      0.94        36\n",
      "   macro avg       0.67      0.97      0.74        36\n",
      "weighted avg       0.98      0.94      0.96        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:electricity\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        31\n",
      "           1       1.00      0.60      0.75         5\n",
      "\n",
      "   micro avg       0.94      0.94      0.94        36\n",
      "   macro avg       0.97      0.80      0.86        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:tools\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        30\n",
      "           1       1.00      0.83      0.91         6\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        36\n",
      "   macro avg       0.98      0.92      0.95        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:hospitals\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        32\n",
      "           1       1.00      0.50      0.67         4\n",
      "\n",
      "   micro avg       0.94      0.94      0.94        36\n",
      "   macro avg       0.97      0.75      0.82        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:shops\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00         3\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:aid_centers\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        33\n",
      "           1       1.00      0.67      0.80         3\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        36\n",
      "   macro avg       0.99      0.83      0.89        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:other_infrastructure\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86        24\n",
      "           1       1.00      0.33      0.50        12\n",
      "\n",
      "   micro avg       0.78      0.78      0.78        36\n",
      "   macro avg       0.88      0.67      0.68        36\n",
      "weighted avg       0.83      0.78      0.74        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:weather_related\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:floods\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:storm\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        36\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:fire\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        36\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.94      0.94      0.94        36\n",
      "   macro avg       0.50      0.47      0.49        36\n",
      "weighted avg       1.00      0.94      0.97        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:earthquake\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        32\n",
      "           1       1.00      0.75      0.86         4\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        36\n",
      "   macro avg       0.98      0.88      0.92        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:cold\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.96        32\n",
      "           1       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        36\n",
      "   macro avg       0.96      0.62      0.68        36\n",
      "weighted avg       0.92      0.92      0.89        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:other_weather\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        36\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        36\n",
      "   macro avg       0.50      0.49      0.49        36\n",
      "weighted avg       1.00      0.97      0.99        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target:direct_report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overall average f1 score of all categories are: 0.9376053201049243\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, X_test, Y_test, category_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = joblib.load(\"model/RF_CV.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(['slightly injured, need help'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///data/DisasterResponse.db')\n",
    "df = pd.read_sql_table('etl_processed_data', engine)\n",
    "\n",
    "\n",
    "query = 'slightly injured, need help'\n",
    "\n",
    "classification_labels = model.predict([query])[0]\n",
    "classification_results = dict(zip(df.columns[4:], classification_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'related': 1,\n",
       " 'request': 1,\n",
       " 'offer': 0,\n",
       " 'aid_related': 1,\n",
       " 'medical_help': 1,\n",
       " 'medical_products': 0,\n",
       " 'search_and_rescue': 0,\n",
       " 'security': 0,\n",
       " 'military': 0,\n",
       " 'child_alone': 0,\n",
       " 'water': 0,\n",
       " 'food': 0,\n",
       " 'shelter': 0,\n",
       " 'clothing': 0,\n",
       " 'money': 0,\n",
       " 'missing_people': 0,\n",
       " 'refugees': 0,\n",
       " 'death': 0,\n",
       " 'other_aid': 0,\n",
       " 'infrastructure_related': 0,\n",
       " 'transport': 0,\n",
       " 'buildings': 0,\n",
       " 'electricity': 0,\n",
       " 'tools': 0,\n",
       " 'hospitals': 0,\n",
       " 'shops': 0,\n",
       " 'aid_centers': 0,\n",
       " 'other_infrastructure': 0,\n",
       " 'weather_related': 0,\n",
       " 'floods': 0,\n",
       " 'storm': 0,\n",
       " 'fire': 0,\n",
       " 'earthquake': 0,\n",
       " 'cold': 0,\n",
       " 'other_weather': 0,\n",
       " 'direct_report': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nltk version is 3.4.\n",
      "The scikit-learn version is 0.20.1.\n",
      "The sqlalchemy version is 1.2.15.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "\n",
    "import sqlalchemy\n",
    "print('The nltk version is {}.'.format(nltk.__version__))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "print('The sqlalchemy version is {}.'.format(sqlalchemy.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
